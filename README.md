# CCF-BDCI2019_Entity_Discovery
CCF-BDCI大数据与计算智能大赛-互联网金融新实体发现-9th
---
# 赛题描述：
提取出每篇文章中所有的金融新实体，  
例如某篇文章的文本如下（此处只做示例，实际每篇文章文本长度远远大于以下示例）：  
度小满金融在首次发布的《科创板基金》中提到，今年前5月，京东金融的股票迅速升值。  
那么该篇文章对应的金融新实体列表为：度小满金融;科创板基金。  
***由于京东金融是知名的（金融）实体，所以“京东金融”并不算新实体。***  

# 个人理解：
结合出题方是“国家互联网应急响应中心”来看，这个赛题的目的实际上是找那种类似校园贷的实体（其实就是不知名的金融实体）。  
**整个赛题要把握住的重点是：**  
①这个赛题实际上偏向于“领域词抽取”（主要针对的是金融领域），但实际上却又不失关键词抽取的要素。  
②注意把握赛题要求中“新实体发现”的“新”，题目中说明了：持有金融牌照的银行、证券、保险、基金等机构、知名的互联网企业如腾讯、淘宝、京东等认为是已知实体（即不能让这些已知实体出现在最终预测结果中）。  

---
# 方案总框架：
使用了深度模型+传统模型  
深度模型：受限于显存的限制，我们只使用了bert_base，并且搭配的下游模型有bilstm+crf（复赛主力模型）（固定参数）以及全连接+crf（初赛主力模型）  
传统模型：只使用了lgb，共100维特征。虽然特征量大，但由于数据量不大，我们造特征所消耗的时间实际上是并不多的。  

---
# 具体解决方案：

## 数据清洗：
因为本赛题的文本数据大都是由爬虫对html抓取的互联网金融文本，故原始数据集的文本非常脏，主要发现的问题如下：  
①文本中有很多超链接    
②表情、特殊符号   
③多个问号（可能是爬取过程中乱码）   
④无意义文本，比如邮箱、电话之类  
我们通过编写脚本对这些文本进行了清洗。  
***特别重要的是，文本不能清洗的特别干净，比如比赛初期我将停用词、除了常用标点（就是回车问号等等一系列的）之外的标点、网页标签都去掉了，把大写的句号全都改成小写的句号（还有大写的逗号，大写的顿号等等），还把所有繁体都转成简体了，这样的预处理所带来的是效果不升反降。因为这些改动实际上都可能会破坏文本原有的结构以及信息，且bert对于停用词、特殊符号等本身就不敏感。    
  
## 数据预处理：  
- 本赛题提供的文本中，有很多文本的长度甚至都超出了2000个字，***而bert读入文本时，都会把文本截断到maxlen长度以下***，所以bert读入超过maxlen长度的文本后，后面的那些文本就直接“抛弃”了。这样就会有一部分数据得不到利用。  
      * 我的解决方法是将长度超过maxlen的文本切成长度都小于maxlen的几个小段。  
      具体做法请参考：roberta预训练中FULL-SENTENCE的数据预处理方法，  
      即用几个连续的句子拼接，直到最大长度512。   
      （这个是我误打误撞想到的，甚至不知道是出自某篇论文。好像前5中也有人用了这个方案。其余很多人都是暴力的直接把句子截到512，但我觉得那种方法可能  
      不能保证语义上的连续性）。  
      * 我队友的方法是使用了句子滑窗（也很有借鉴意义），就是例如有句子序列ABCDEF……，若ABCD组成的段能正好小于maxlen，接下来就按固定的句子数滑窗，
      比如向前滑两句，即句子的开头由A滑到C，从C开始填充512，即看看CD、CDE、CDEF……直到填充满512为止。 
      这个方法是一种既保留了句子原连续语义，又在一定程度上进行了数据增广。然而在我自己的方案（固定参数bert-bilstm-crf）中，并没有得到效果提升。
  

## 深度模型选择：
 - 我们的语言模型选择了bert-base，主要原因还是我们的机器跑不动roberta-large的512长度。而哈工大的bert-wwm我尝试过，效果并不比bert-base要好  
 这就导致了我们的深度模型与top队伍深度模型的差距（top队伍赛后总结中基本都写到用roberta-large或者bert-wwm来搞。）  
  
## 初赛方案：
### 正负样本均衡：
原始数据中，存在一部分没有被标注出新实体的样本，这一部分样本我在最一开始的时候是直接去掉不要的，且我将文本都切分到maxlen以下后，也会产生不少这样的样本。
后来观察了一下，发现那部分样本存在很多的知名实体（已知实体），这也是这些样本没有被标注的原因。  
- 我的方案是试做下采样，即只取一部分负样本，经过试验，发现使正负样本比例保持在8：1左右。结果使线上效果又上升了0.5个百分点。  
- 我队友的方案：由于他的maxlen取的比较小，这也导致他负样本非常多，正负样本比例达到了1：2，他是做了上采样，将正样例加了3倍，使正负样本比例到了3：2.  

### 数据标注格式：
- 最初采用了bio格式，但观察模型输出结果，我发现有很多 BOIIIO……这样的情况，后期换成了BIOES标注，这也带来了2~3个千分点提升。  

### 模型预训练：
- 我的方案：下载谷歌官方的预训练模型，并在此基础上按照roberta训练方式进行预训练（没有全词mask，去掉NSP（next sentence predict）任务的loss，使用FULL-SENTENCE（上面有提到）而不是谷歌官方提供的“将文章分为一个个句子”）。效果出奇的好，单模效果非常稳定（原来提交结果线上波动非常大），在f1 32左右（线上排名前5）。  
- 我队友的方案：直接使用谷歌官方的预训练方式，但是也去掉NSP任务。  

### 下游模型选择:
- 我的方案是：bilstm+crf，固定bert参数。该方案识别出来的实体非常多，但是却并不是那么精准（比如有“广州市创鑫软件科技有限公司是金融公司”）。  
- 我队友的方案：全连接+crf，不固定bert参数。该方案识别出来的实体比我的少很多，但是却非常精准，没有上面说的那种杂乱的实体。（我曾经使用过相同的样本采样方式，用我队友的模型来训练，得到的样本数一样非常少，所以可以排除数据处理、样本采样带来的影响）  

### 

